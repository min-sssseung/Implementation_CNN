{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inception으로 dimension reduction 해주는 부분\n",
    "# Figure 2 의 (b)로 구현\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self,in_channels,out_1x1,reduce_3x3,out_3x3,reduce_5x5,out_5x5,pooling):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1x1 conv층만\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_1x1,kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # 1x1 conv -> 3x3 conv층\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,reduce_3x3,kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(reduce_3x3,out_3x3,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # 1x1 conv -> 5x5 conv층\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,reduce_5x5,kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(reduce_5x5,out_5x5,kernel_size=5,stride=1,padding=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # 3x3 maxpooling -> 1x1 conv층\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3,stride=1,padding=1),\n",
    "            nn.Conv2d(in_channels,pooling,kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        out1 = self.branch1(x)\n",
    "        out2 = self.branch2(x)\n",
    "        out3 = self.branch3(x)\n",
    "        out4 = self.branch4(x)\n",
    "        # concatenating\n",
    "        return torch.cat([out1,out2,out3,out4],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inception 전까지\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3,64,kernel_size=7,stride=2,padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2,padding=1),\n",
    "            nn.Conv2d(64,192,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2,padding=1),\n",
    "        )\n",
    "        # Inception 3a,3b maxpool까지\n",
    "        self.layer2 = nn.Sequential(\n",
    "            Inception(192,64,96,128,16,32,32),\n",
    "            Inception(256,128,128,192,32,96,64),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "        )\n",
    "        # Inception 4a,4b,4c,4d,4e,maxpool까지\n",
    "        self.layer3 = nn.Sequential(\n",
    "            Inception(480,192,96,208,16,48,64),\n",
    "            Inception(512,160,112,224,24,64,64), \n",
    "            Inception(512,128,128,256,24,64,64),\n",
    "            Inception(512,112,144,288,32,64,64),\n",
    "            Inception(528,256,160,320,32,128,128),  \n",
    "            nn.MaxPool2d(kernel_size=3,stride=2,padding=1),\n",
    "        )\n",
    "        # Inception 5a,5b,avgpool까지\n",
    "        self.layer4 = nn.Sequential(\n",
    "            # Inception 5a,5b,avgpool\n",
    "            Inception(832,256,160,320,32,128,128),\n",
    "            Inception(832,384,192,384,48,128,128),\n",
    "            nn.AdaptiveAvgPool2d((1,1))\n",
    "        )\n",
    "        self.dropout = nn.Dropout2d(p = 0.4)\n",
    "        self.fc = nn.Linear(1024,1000)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size()[0],-1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "model = GoogleNet()\n",
    "img = torch.rand((1,3,224,224))\n",
    "output = model(img)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,472\n",
      "              ReLU-2         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-3           [-1, 64, 56, 56]               0\n",
      "            Conv2d-4          [-1, 192, 56, 56]         110,784\n",
      "              ReLU-5          [-1, 192, 56, 56]               0\n",
      "         MaxPool2d-6          [-1, 192, 28, 28]               0\n",
      "            Conv2d-7           [-1, 64, 28, 28]          12,352\n",
      "              ReLU-8           [-1, 64, 28, 28]               0\n",
      "            Conv2d-9           [-1, 96, 28, 28]          18,528\n",
      "             ReLU-10           [-1, 96, 28, 28]               0\n",
      "           Conv2d-11          [-1, 128, 28, 28]         110,720\n",
      "             ReLU-12          [-1, 128, 28, 28]               0\n",
      "           Conv2d-13           [-1, 16, 28, 28]           3,088\n",
      "             ReLU-14           [-1, 16, 28, 28]               0\n",
      "           Conv2d-15           [-1, 32, 28, 28]          12,832\n",
      "             ReLU-16           [-1, 32, 28, 28]               0\n",
      "        MaxPool2d-17          [-1, 192, 28, 28]               0\n",
      "           Conv2d-18           [-1, 32, 28, 28]           6,176\n",
      "             ReLU-19           [-1, 32, 28, 28]               0\n",
      "        Inception-20          [-1, 256, 28, 28]               0\n",
      "           Conv2d-21          [-1, 128, 28, 28]          32,896\n",
      "             ReLU-22          [-1, 128, 28, 28]               0\n",
      "           Conv2d-23          [-1, 128, 28, 28]          32,896\n",
      "             ReLU-24          [-1, 128, 28, 28]               0\n",
      "           Conv2d-25          [-1, 192, 28, 28]         221,376\n",
      "             ReLU-26          [-1, 192, 28, 28]               0\n",
      "           Conv2d-27           [-1, 32, 28, 28]           8,224\n",
      "             ReLU-28           [-1, 32, 28, 28]               0\n",
      "           Conv2d-29           [-1, 96, 28, 28]          76,896\n",
      "             ReLU-30           [-1, 96, 28, 28]               0\n",
      "        MaxPool2d-31          [-1, 256, 28, 28]               0\n",
      "           Conv2d-32           [-1, 64, 28, 28]          16,448\n",
      "             ReLU-33           [-1, 64, 28, 28]               0\n",
      "        Inception-34          [-1, 480, 28, 28]               0\n",
      "        MaxPool2d-35          [-1, 480, 14, 14]               0\n",
      "           Conv2d-36          [-1, 192, 14, 14]          92,352\n",
      "             ReLU-37          [-1, 192, 14, 14]               0\n",
      "           Conv2d-38           [-1, 96, 14, 14]          46,176\n",
      "             ReLU-39           [-1, 96, 14, 14]               0\n",
      "           Conv2d-40          [-1, 208, 14, 14]         179,920\n",
      "             ReLU-41          [-1, 208, 14, 14]               0\n",
      "           Conv2d-42           [-1, 16, 14, 14]           7,696\n",
      "             ReLU-43           [-1, 16, 14, 14]               0\n",
      "           Conv2d-44           [-1, 48, 14, 14]          19,248\n",
      "             ReLU-45           [-1, 48, 14, 14]               0\n",
      "        MaxPool2d-46          [-1, 480, 14, 14]               0\n",
      "           Conv2d-47           [-1, 64, 14, 14]          30,784\n",
      "             ReLU-48           [-1, 64, 14, 14]               0\n",
      "        Inception-49          [-1, 512, 14, 14]               0\n",
      "           Conv2d-50          [-1, 160, 14, 14]          82,080\n",
      "             ReLU-51          [-1, 160, 14, 14]               0\n",
      "           Conv2d-52          [-1, 112, 14, 14]          57,456\n",
      "             ReLU-53          [-1, 112, 14, 14]               0\n",
      "           Conv2d-54          [-1, 224, 14, 14]         226,016\n",
      "             ReLU-55          [-1, 224, 14, 14]               0\n",
      "           Conv2d-56           [-1, 24, 14, 14]          12,312\n",
      "             ReLU-57           [-1, 24, 14, 14]               0\n",
      "           Conv2d-58           [-1, 64, 14, 14]          38,464\n",
      "             ReLU-59           [-1, 64, 14, 14]               0\n",
      "        MaxPool2d-60          [-1, 512, 14, 14]               0\n",
      "           Conv2d-61           [-1, 64, 14, 14]          32,832\n",
      "             ReLU-62           [-1, 64, 14, 14]               0\n",
      "        Inception-63          [-1, 512, 14, 14]               0\n",
      "           Conv2d-64          [-1, 128, 14, 14]          65,664\n",
      "             ReLU-65          [-1, 128, 14, 14]               0\n",
      "           Conv2d-66          [-1, 128, 14, 14]          65,664\n",
      "             ReLU-67          [-1, 128, 14, 14]               0\n",
      "           Conv2d-68          [-1, 256, 14, 14]         295,168\n",
      "             ReLU-69          [-1, 256, 14, 14]               0\n",
      "           Conv2d-70           [-1, 24, 14, 14]          12,312\n",
      "             ReLU-71           [-1, 24, 14, 14]               0\n",
      "           Conv2d-72           [-1, 64, 14, 14]          38,464\n",
      "             ReLU-73           [-1, 64, 14, 14]               0\n",
      "        MaxPool2d-74          [-1, 512, 14, 14]               0\n",
      "           Conv2d-75           [-1, 64, 14, 14]          32,832\n",
      "             ReLU-76           [-1, 64, 14, 14]               0\n",
      "        Inception-77          [-1, 512, 14, 14]               0\n",
      "           Conv2d-78          [-1, 112, 14, 14]          57,456\n",
      "             ReLU-79          [-1, 112, 14, 14]               0\n",
      "           Conv2d-80          [-1, 144, 14, 14]          73,872\n",
      "             ReLU-81          [-1, 144, 14, 14]               0\n",
      "           Conv2d-82          [-1, 288, 14, 14]         373,536\n",
      "             ReLU-83          [-1, 288, 14, 14]               0\n",
      "           Conv2d-84           [-1, 32, 14, 14]          16,416\n",
      "             ReLU-85           [-1, 32, 14, 14]               0\n",
      "           Conv2d-86           [-1, 64, 14, 14]          51,264\n",
      "             ReLU-87           [-1, 64, 14, 14]               0\n",
      "        MaxPool2d-88          [-1, 512, 14, 14]               0\n",
      "           Conv2d-89           [-1, 64, 14, 14]          32,832\n",
      "             ReLU-90           [-1, 64, 14, 14]               0\n",
      "        Inception-91          [-1, 528, 14, 14]               0\n",
      "           Conv2d-92          [-1, 256, 14, 14]         135,424\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 160, 14, 14]          84,640\n",
      "             ReLU-95          [-1, 160, 14, 14]               0\n",
      "           Conv2d-96          [-1, 320, 14, 14]         461,120\n",
      "             ReLU-97          [-1, 320, 14, 14]               0\n",
      "           Conv2d-98           [-1, 32, 14, 14]          16,928\n",
      "             ReLU-99           [-1, 32, 14, 14]               0\n",
      "          Conv2d-100          [-1, 128, 14, 14]         102,528\n",
      "            ReLU-101          [-1, 128, 14, 14]               0\n",
      "       MaxPool2d-102          [-1, 528, 14, 14]               0\n",
      "          Conv2d-103          [-1, 128, 14, 14]          67,712\n",
      "            ReLU-104          [-1, 128, 14, 14]               0\n",
      "       Inception-105          [-1, 832, 14, 14]               0\n",
      "       MaxPool2d-106            [-1, 832, 7, 7]               0\n",
      "          Conv2d-107            [-1, 256, 7, 7]         213,248\n",
      "            ReLU-108            [-1, 256, 7, 7]               0\n",
      "          Conv2d-109            [-1, 160, 7, 7]         133,280\n",
      "            ReLU-110            [-1, 160, 7, 7]               0\n",
      "          Conv2d-111            [-1, 320, 7, 7]         461,120\n",
      "            ReLU-112            [-1, 320, 7, 7]               0\n",
      "          Conv2d-113             [-1, 32, 7, 7]          26,656\n",
      "            ReLU-114             [-1, 32, 7, 7]               0\n",
      "          Conv2d-115            [-1, 128, 7, 7]         102,528\n",
      "            ReLU-116            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-117            [-1, 832, 7, 7]               0\n",
      "          Conv2d-118            [-1, 128, 7, 7]         106,624\n",
      "            ReLU-119            [-1, 128, 7, 7]               0\n",
      "       Inception-120            [-1, 832, 7, 7]               0\n",
      "          Conv2d-121            [-1, 384, 7, 7]         319,872\n",
      "            ReLU-122            [-1, 384, 7, 7]               0\n",
      "          Conv2d-123            [-1, 192, 7, 7]         159,936\n",
      "            ReLU-124            [-1, 192, 7, 7]               0\n",
      "          Conv2d-125            [-1, 384, 7, 7]         663,936\n",
      "            ReLU-126            [-1, 384, 7, 7]               0\n",
      "          Conv2d-127             [-1, 48, 7, 7]          39,984\n",
      "            ReLU-128             [-1, 48, 7, 7]               0\n",
      "          Conv2d-129            [-1, 128, 7, 7]         153,728\n",
      "            ReLU-130            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-131            [-1, 832, 7, 7]               0\n",
      "          Conv2d-132            [-1, 128, 7, 7]         106,624\n",
      "            ReLU-133            [-1, 128, 7, 7]               0\n",
      "       Inception-134           [-1, 1024, 7, 7]               0\n",
      "AdaptiveAvgPool2d-135           [-1, 1024, 1, 1]               0\n",
      "       Dropout2d-136           [-1, 1024, 1, 1]               0\n",
      "          Linear-137                 [-1, 1000]       1,025,000\n",
      "================================================================\n",
      "Total params: 6,994,392\n",
      "Trainable params: 6,994,392\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 66.43\n",
      "Params size (MB): 26.68\n",
      "Estimated Total Size (MB): 93.68\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3,224,224))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
